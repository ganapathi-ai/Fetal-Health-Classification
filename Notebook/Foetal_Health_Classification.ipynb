{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data and Initial Setup"
      ],
      "metadata": {
        "id": "TUVn-hWAbU9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/fetal_health.csv')"
      ],
      "metadata": {
        "id": "oE1wDFt2RX9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E0lTlPZmRcFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b14c933"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "print(\"Libraries imported successfully.\")\n",
        "\n",
        "print(\"\\nFirst 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nConcise summary of the DataFrame:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nDescriptive statistics of the DataFrame:\")\n",
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649db911"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fc070b9"
      },
      "source": [
        "X = df.drop('fetal_health', axis=1)\n",
        "y = df['fetal_health']\n",
        "\n",
        "print(\"Features (X) shape:\", X.shape)\n",
        "print(\"Target (y) shape:\", y.shape)\n",
        "\n",
        "print(\"\\nChecking for missing values in X:\")\n",
        "print(X.isnull().sum().sum())\n",
        "\n",
        "print(\"\\nChecking for missing values in y:\")\n",
        "print(y.isnull().sum().sum())\n",
        "\n",
        "# Outlier detection and treatment using IQR\n",
        "for column in X.columns:\n",
        "    if X[column].dtype in ['float64', 'int64']:\n",
        "        Q1 = X[column].quantile(0.25)\n",
        "        Q3 = X[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Replace outliers with the median\n",
        "        median_val = X[column].median()\n",
        "        X[column] = np.where(X[column] < lower_bound, median_val,\n",
        "                             np.where(X[column] > upper_bound, median_val, X[column]))\n",
        "print(\"\\nOutliers treated using IQR method. All values outside 1.5*IQR bounds replaced with column median.\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"\\nFeatures scaled using StandardScaler. First 5 rows of X_scaled:\")\n",
        "print(X_scaled.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfa43dbe"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "883e9208"
      },
      "source": [
        "df['fetal_health'] = df['fetal_health'].astype(int)\n",
        "print(\"Converted 'fetal_health' column to integer type in df.\")\n",
        "print(df['fetal_health'].value_counts())\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(20, 18))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix of Fetal Health Dataset Features')\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The correlation matrix heatmap shows the pairwise correlation coefficients between all features in the dataset. Positive values indicate a positive correlation, negative values indicate a negative correlation, and values close to zero suggest a weak linear relationship. The 'fetal_health' row/column is particularly important, as it reveals which features are most strongly correlated with the target variable. For example, 'abnormal_short_term_variability' and 'prolongued_decelerations' might show strong positive correlations with 'fetal_health' (higher values indicating worse health), while 'accelerations' might show a strong negative correlation (higher values indicating better health). This visualization helps in understanding feature dependencies and selecting relevant features for modeling.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac0a5e55"
      },
      "source": [
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "# lmplot for 'baseline value' vs 'fetal_health'\n",
        "sns.lmplot(x='baseline value', y='fetal_health', data=df, aspect=1.5)\n",
        "plt.title('Linear Relationship between Baseline Value and Fetal Health')\n",
        "plt.xlabel('Baseline Value')\n",
        "plt.ylabel('Fetal Health Outcome')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The lmplot for 'baseline value' and 'fetal_health' shows a slight positive linear trend. As the baseline value increases, there's a tendency for the fetal health outcome to shift towards higher categories (i.e., less healthy). However, there is significant overlap and spread, indicating that 'baseline value' alone is not a strong predictor, but higher baseline values are more frequently associated with abnormal fetal health.\")\n",
        "\n",
        "# lmplot for 'accelerations' vs 'fetal_health'\n",
        "sns.lmplot(x='accelerations', y='fetal_health', data=df, aspect=1.5)\n",
        "plt.title('Linear Relationship between Accelerations and Fetal Health')\n",
        "plt.xlabel('Accelerations')\n",
        "plt.ylabel('Fetal Health Outcome')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The lmplot for 'accelerations' and 'fetal_health' shows a negative linear trend. Higher acceleration values are generally associated with lower fetal health outcomes (i.e., healthier babies). This suggests that a higher number of accelerations might be indicative of a healthier fetus. However, the data points are very spread out, especially for lower acceleration values, and the relationship isn't very strong.\")\n",
        "\n",
        "# lmplot for 'uterine_contractions' vs 'fetal_health'\n",
        "sns.lmplot(x='uterine_contractions', y='fetal_health', data=df, aspect=1.5)\n",
        "plt.title('Linear Relationship between Uterine Contractions and Fetal Health')\n",
        "plt.xlabel('Uterine Contractions')\n",
        "plt.ylabel('Fetal Health Outcome')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The lmplot for 'uterine_contractions' and 'fetal_health' shows a very weak, almost negligible, positive linear trend. While there's a slight tendency for fetal health outcomes to increase with more uterine contractions, the relationship is not clear and highly scattered. This feature does not appear to be a strong linear indicator of fetal health.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9078957a"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, I will now generate `swarmplot` visualizations to show the distribution of data points for 'fetal_health' across 'mean_value_of_short_term_variability' and 'histogram_min', providing interpretations for each.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c566e7e9"
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Swarmplot for 'mean_value_of_short_term_variability' vs 'fetal_health'\n",
        "sns.swarmplot(x='fetal_health', y='mean_value_of_short_term_variability', data=df, palette='viridis')\n",
        "plt.title('Distribution of Mean Value of Short Term Variability by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Mean Value of Short Term Variability')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The swarmplot for 'mean_value_of_short_term_variability' against 'fetal_health' shows distinct distributions for each health category. For Fetal Health 1 (Normal), the values are concentrated at higher short-term variability, indicating good health. As fetal health deteriorates (Fetal Health 2: Suspect, Fetal Health 3: Pathological), the mean value of short-term variability tends to decrease and become more tightly clustered at lower values. This suggests that lower short-term variability is associated with poorer fetal health outcomes.\")\n",
        "\n",
        "# Swarmplot for 'histogram_min' vs 'fetal_health'\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.swarmplot(x='fetal_health', y='histogram_min', data=df, palette='magma')\n",
        "plt.title('Distribution of Histogram Min by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Min')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The swarmplot for 'histogram_min' against 'fetal_health' reveals that Fetal Health 1 (Normal) has a wider spread of histogram_min values, with many data points at lower heart rates. For Fetal Health 2 (Suspect) and Fetal Health 3 (Pathological), the distribution shifts towards higher histogram_min values, and the spread narrows, indicating less variability and potentially higher baseline fetal heart rates during periods of distress. This suggests that higher histogram_min values are more common in less healthy fetuses.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3313993"
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Swarmplot for 'mean_value_of_short_term_variability' vs 'fetal_health'\n",
        "sns.swarmplot(x='fetal_health', y='mean_value_of_short_term_variability', data=df, palette='viridis', hue='fetal_health', legend=False)\n",
        "plt.title('Distribution of Mean Value of Short Term Variability by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Mean Value of Short Term Variability')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The swarmplot for 'mean_value_of_short_term_variability' against 'fetal_health' shows distinct distributions for each health category. For Fetal Health 1 (Normal), the values are concentrated at higher short-term variability, indicating good health. As fetal health deteriorates (Fetal Health 2: Suspect, Fetal Health 3: Pathological), the mean value of short-term variability tends to decrease and become more tightly clustered at lower values. This suggests that lower short-term variability is associated with poorer fetal health outcomes. The user warning regarding overlapping points indicates the density of the data, which can make individual points hard to distinguish.\")\n",
        "\n",
        "# Swarmplot for 'histogram_min' vs 'fetal_health'\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.swarmplot(x='fetal_health', y='histogram_min', data=df, palette='magma', hue='fetal_health', legend=False)\n",
        "plt.title('Distribution of Histogram Min by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Min')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The swarmplot for 'histogram_min' against 'fetal_health' reveals that Fetal Health 1 (Normal) has a wider spread of histogram_min values, with many data points at lower heart rates. For Fetal Health 2 (Suspect) and Fetal Health 3 (Pathological), the distribution shifts towards higher histogram_min values, and the spread narrows, indicating less variability and potentially higher baseline fetal heart rates during periods of distress. This suggests that higher histogram_min values are more common in less healthy fetuses. Similar to the previous plot, the user warning about unplaced points highlights the concentration of data at certain values.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae7c4b42"
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Boxplot for 'histogram_variance' vs 'fetal_health'\n",
        "sns.boxplot(x='fetal_health', y='histogram_variance', data=df, palette='viridis')\n",
        "plt.title('Distribution of Histogram Variance by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Variance')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The boxplot for 'histogram_variance' against 'fetal_health' indicates clear differences across health categories. For Fetal Health 1 (Normal), the variance is generally lower, with a tighter interquartile range and fewer extreme outliers. As fetal health deteriorates (Fetal Health 2 and 3), the median histogram variance tends to increase, and the spread (IQR) becomes larger, suggesting greater variability in heart rate. There are also more noticeable outliers with higher variance in the less healthy categories, indicating episodes of significant heart rate fluctuations.\")\n",
        "\n",
        "# Boxplot for 'histogram_mode' vs 'fetal_health'\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.boxplot(x='fetal_health', y='histogram_mode', data=df, palette='magma')\n",
        "plt.title('Distribution of Histogram Mode by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Mode')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The boxplot for 'histogram_mode' against 'fetal_health' shows a general trend where the mode of the heart rate histogram decreases as fetal health deteriorates. Fetal Health 1 (Normal) has a higher median mode, indicating a more stable and higher typical heart rate. Fetal Health 2 (Suspect) and Fetal Health 3 (Pathological) show progressively lower median modes, suggesting a shift towards lower central heart rate values. The spread of the data also changes, with Fetal Health 3 having a somewhat wider IQR and more outliers at lower modes, indicating greater heart rate instability in pathological cases.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9339d45"
      },
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Boxplot for 'histogram_variance' vs 'fetal_health'\n",
        "sns.boxplot(x='fetal_health', y='histogram_variance', data=df, palette='viridis', hue='fetal_health', legend=False)\n",
        "plt.title('Distribution of Histogram Variance by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Variance')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The boxplot for 'histogram_variance' against 'fetal_health' indicates clear differences across health categories. For Fetal Health 1 (Normal), the variance is generally lower, with a tighter interquartile range and fewer extreme outliers. As fetal health deteriorates (Fetal Health 2 and 3), the median histogram variance tends to increase, and the spread (IQR) becomes larger, suggesting greater variability in heart rate. There are also more noticeable outliers with higher variance in the less healthy categories, indicating episodes of significant heart rate fluctuations.\")\n",
        "\n",
        "# Boxplot for 'histogram_mode' vs 'fetal_health'\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.boxplot(x='fetal_health', y='histogram_mode', data=df, palette='magma', hue='fetal_health', legend=False)\n",
        "plt.title('Distribution of Histogram Mode by Fetal Health')\n",
        "plt.xlabel('Fetal Health Outcome (1: Normal, 2: Suspect, 3: Pathological)')\n",
        "plt.ylabel('Histogram Mode')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Interpretation: The boxplot for 'histogram_mode' against 'fetal_health' shows a general trend where the mode of the heart rate histogram decreases as fetal health deteriorates. Fetal Health 1 (Normal) has a higher median mode, indicating a more stable and higher typical heart rate. Fetal Health 2 (Suspect) and Fetal Health 3 (Pathological) show progressively lower median modes, suggesting a shift towards lower central heart rate values. The spread of the data also changes, with Fetal Health 3 having a somewhat wider IQR and more outliers at lower modes, indicating greater heart rate instability in pathological cases.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c71fa25"
      },
      "source": [
        "## Model Training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105e9177"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# 1. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Data split into training and testing sets successfully.\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# 2. Initialize the classification models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\nTraining models and evaluating performance...\")\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    # 3. Train each model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 4. Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 5. Calculate and print evaluation metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'report': report,\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Plot Confusion Matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=['Normal (1)', 'Suspect (2)', 'Pathological (3)'],\n",
        "                yticklabels=['Normal (1)', 'Suspect (2)', 'Pathological (3)'])\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a93a9616"
      },
      "source": [
        "## Hyperparameter Tuning and Best Model Selection\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ea96896"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grids for each model\n",
        "param_grid_lr = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'lbfgs']\n",
        "}\n",
        "\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "print(\"GridSearchCV imported and parameter grids defined for Logistic Regression, SVM, Random Forest, and Gradient Boosting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aafef403"
      },
      "source": [
        "tuned_models = {}\n",
        "best_scores = {}\n",
        "\n",
        "# Dictionary of models and their respective parameter grids\n",
        "models_to_tune = {\n",
        "    'Logistic Regression': (LogisticRegression(max_iter=1000, random_state=42), param_grid_lr),\n",
        "    'SVM': (SVC(random_state=42), param_grid_svm),\n",
        "    'Random Forest': (RandomForestClassifier(random_state=42), param_grid_rf),\n",
        "    'Gradient Boosting': (GradientBoostingClassifier(random_state=42), param_grid_gb)\n",
        "}\n",
        "\n",
        "print(\"Starting hyperparameter tuning for each model...\")\n",
        "\n",
        "for name, (model, param_grid) in models_to_tune.items():\n",
        "    print(f\"\\n--- Tuning {name} ---\")\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "    print(f\"Best cross-validation accuracy for {name}: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    tuned_models[name] = grid_search.best_estimator_\n",
        "    best_scores[name] = grid_search.best_score_\n",
        "\n",
        "print(\"\\n--- Hyperparameter Tuning Complete ---\")\n",
        "\n",
        "# Compare tuned models and select the best one\n",
        "best_model_name = max(best_scores, key=best_scores.get)\n",
        "best_model = tuned_models[best_model_name]\n",
        "\n",
        "print(f\"\\nOverall best performing model: {best_model_name}\")\n",
        "print(f\"Best cross-validation accuracy: {best_scores[best_model_name]:.4f}\")\n",
        "print(\"Selected best model and stored it as 'best_model' for deployment.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion matrix for best model"
      ],
      "metadata": {
        "id": "nJHsBd9SgaOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set using the best model\n",
        "y_pred_best_model = best_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm_best_model = confusion_matrix(y_test, y_pred_best_model)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_best_model, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Normal (1)', 'Suspect (2)', 'Pathological (3)'],\n",
        "            yticklabels=['Normal (1)', 'Suspect (2)', 'Pathological (3)'])\n",
        "plt.title(f'Confusion Matrix - {best_model_name} (Best Tuned Model)')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Interpretation: The confusion matrix for the best-tuned {best_model_name} model visually represents its performance on the test set. Each row corresponds to the true class, while each column represents the predicted class. The diagonal elements show the number of correctly classified instances for each class. Off-diagonal elements indicate misclassifications. For example, a high number in the cell (True: Suspect, Predicted: Normal) would indicate that the model frequently misclassifies Suspect cases as Normal. This matrix provides a detailed breakdown of the model's predictive accuracy and its ability to distinguish between the three fetal health outcomes.\")"
      ],
      "metadata": {
        "id": "g_HOjyeQgPPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5540f9e"
      },
      "source": [
        "## Save Best Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd084509"
      },
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best-performing model to a file\n",
        "model_filename = 'best_fetal_health_model.joblib'\n",
        "joblib.dump(best_model, model_filename)\n",
        "\n",
        "print(f\"Best model '{best_model_name}' saved to {model_filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "828a98f9"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# 1. Install pyngrok\n",
        "!pip install pyngrok\n",
        "print(\"pyngrok installed successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ab16fd"
      },
      "source": [
        "os.environ['NGROK_AUTH_TOKEN'] = '37yofC2Qh6BykHXZNlTF7qEGEa6_387qPPWND9fU3zhAV8GYL'\n",
        "print(\"NGROK_AUTH_TOKEN environment variable updated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5820b68"
      },
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Install Streamlit\n",
        "!pip install streamlit\n",
        "print(\"Streamlit installed successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ac294ab"
      },
      "source": [
        "## Save Fitted Scaler\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbc6efe9"
      },
      "source": [
        "import joblib\n",
        "\n",
        "# Save the fitted scaler object to a file\n",
        "scaler_filename = 'scaler.joblib'\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "\n",
        "print(f\"Fitted scaler saved to {scaler_filename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8998e4e1"
      },
      "source": [
        "## Streamlit Dashboard Development\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a59ef4b"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained model and scaler\n",
        "model = joblib.load('best_fetal_health_model.joblib')\n",
        "scaler = joblib.load('scaler.joblib') # Load the saved scaler\n",
        "\n",
        "st.set_page_config(page_title=\"Fetal Health Prediction\", layout=\"wide\")\n",
        "st.title(\"Fetal Health Classification\")\n",
        "st.markdown(\"Predict the health outcome of a fetus based on CTG (Cardiotocography) parameters.\")\n",
        "\n",
        "# Define the feature names in the correct order as per the training data\n",
        "# Since X is not directly available in app.py, we need to infer column names from the model or load them.\n",
        "# For consistency, we can assume the order of features is the same as the original df columns excluding the target.\n",
        "# A more robust solution would be to save feature names alongside the model/scaler.\n",
        "# For now, let's re-define them based on the context of the notebook before this app.py generation.\n",
        "feature_names = ['baseline value', 'accelerations', 'fetal_movement', 'uterine_contractions',\n",
        "                 'light_decelerations', 'severe_decelerations', 'prolongued_decelerations',\n",
        "                 'abnormal_short_term_variability', 'mean_value_of_short_term_variability',\n",
        "                 'percentage_of_time_with_abnormal_long_term_variability',\n",
        "                 'mean_value_of_long_term_variability', 'histogram_width', 'histogram_min',\n",
        "                 'histogram_max', 'histogram_number_of_peaks', 'histogram_number_of_zeroes',\n",
        "                 'histogram_mode', 'histogram_mean', 'histogram_median', 'histogram_variance',\n",
        "                 'histogram_tendency']\n",
        "\n",
        "# --- User Input Section ---\n",
        "st.sidebar.header(\"Input Fetal CTG Parameters\")\n",
        "\n",
        "# Dictionary to store user inputs\n",
        "user_inputs = {}\n",
        "\n",
        "# Create sliders for each feature (using dummy min/max/mean for initial app.py generation)\n",
        "# In a real app, these values would ideally come from the training data statistics.\n",
        "# For now, approximate ranges will be used, as the actual `df` is not available in app.py scope.\n",
        "\n",
        "# Using estimated ranges for the sliders. In a production app, these would be explicitly saved/loaded.\n",
        "# For 'fetal_movement', 'severe_decelerations', 'light_decelerations', 'prolongued_decelerations', 'accelerations', 'uterine_contractions'\n",
        "# Assuming typical small float ranges.\n",
        "# For 'histogram_number_of_peaks', 'histogram_number_of_zeroes'\n",
        "# Assuming typical integer ranges.\n",
        "\n",
        "# Example approximations (these would ideally be loaded from a config or saved stats):\n",
        "feature_ranges = {\n",
        "    'baseline value': (100.0, 180.0, 133.0),\n",
        "    'accelerations': (0.0, 0.02, 0.003),\n",
        "    'fetal_movement': (0.0, 0.1, 0.009),\n",
        "    'uterine_contractions': (0.0, 0.02, 0.004),\n",
        "    'light_decelerations': (0.0, 0.02, 0.002),\n",
        "    'severe_decelerations': (0.0, 0.001, 0.0),\n",
        "    'prolongued_decelerations': (0.0, 0.005, 0.0001),\n",
        "    'abnormal_short_term_variability': (10.0, 90.0, 47.0),\n",
        "    'mean_value_of_short_term_variability': (0.0, 7.0, 1.3),\n",
        "    'percentage_of_time_with_abnormal_long_term_variability': (0.0, 100.0, 10.0),\n",
        "    'mean_value_of_long_term_variability': (0.0, 50.0, 4.0),\n",
        "    'histogram_width': (0.0, 180.0, 70.0),\n",
        "    'histogram_min': (50.0, 160.0, 93.0),\n",
        "    'histogram_max': (120.0, 240.0, 164.0),\n",
        "    'histogram_number_of_peaks': (0.0, 20.0, 4.0),\n",
        "    'histogram_number_of_zeroes': (0.0, 10.0, 0.3),\n",
        "    'histogram_mode': (60.0, 190.0, 137.0),\n",
        "    'histogram_mean': (70.0, 190.0, 135.0),\n",
        "    'histogram_median': (70.0, 190.0, 138.0),\n",
        "    'histogram_variance': (0.0, 300.0, 19.0),\n",
        "    'histogram_tendency': (-1.0, 1.0, 0.0)\n",
        "}\n",
        "\n",
        "for feature in feature_names:\n",
        "    min_val, max_val, mean_val = feature_ranges.get(feature, (0.0, 1.0, 0.5)) # Default to 0-1 if not found\n",
        "\n",
        "    if feature in ['fetal_movement', 'severe_decelerations', 'light_decelerations', 'prolongued_decelerations', 'accelerations', 'uterine_contractions']:\n",
        "        user_inputs[feature] = st.sidebar.slider(\n",
        "            f\"{feature.replace('_', ' ').title()}\",\n",
        "            min_val, max_val, float(mean_val), step=0.001, format='%.3f'\n",
        "        )\n",
        "    elif feature in ['histogram_number_of_peaks', 'histogram_number_of_zeroes']:\n",
        "        user_inputs[feature] = st.sidebar.slider(\n",
        "            f\"{feature.replace('_', ' ').title()}\",\n",
        "            min_val, max_val, float(round(mean_val)), step=1.0\n",
        "        )\n",
        "    elif feature == 'histogram_tendency': # This feature has -1, 0, 1 values\n",
        "         user_inputs[feature] = st.sidebar.slider(\n",
        "            f\"{feature.replace('_', ' ').title()}\",\n",
        "            -1.0, 1.0, 0.0, step=1.0\n",
        "        )\n",
        "    else:\n",
        "        user_inputs[feature] = st.sidebar.slider(\n",
        "            f\"{feature.replace('_', ' ').title()}\",\n",
        "            min_val, max_val, mean_val, step=(max_val - min_val) / 100.0\n",
        "        )\n",
        "\n",
        "# --- Prediction Section ---\n",
        "if st.sidebar.button('Predict Fetal Health'):\n",
        "    # Convert user inputs to a DataFrame\n",
        "    input_df = pd.DataFrame([user_inputs])\n",
        "\n",
        "    # Scale the input data\n",
        "    scaled_input = scaler.transform(input_df)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(scaled_input)\n",
        "    prediction_proba = model.predict_proba(scaled_input)\n",
        "\n",
        "    # Map numerical prediction to meaningful labels\n",
        "    fetal_health_map = {\n",
        "        1: 'Normal (1)',\n",
        "        2: 'Suspect (2)',\n",
        "        3: 'Pathological (3)'\n",
        "    }\n",
        "    predicted_class = fetal_health_map.get(int(prediction[0]), 'Unknown')\n",
        "\n",
        "    st.subheader(\"Prediction Result\")\n",
        "    st.success(f\"The predicted fetal health outcome is: **{predicted_class}**\")\n",
        "\n",
        "    st.subheader(\"Prediction Probabilities\")\n",
        "    proba_df = pd.DataFrame(prediction_proba, columns=['Normal', 'Suspect', 'Pathological'])\n",
        "    st.write(proba_df)\n",
        "\n",
        "st.header(\"About the Model and Data\")\n",
        "st.markdown(\n",
        "    \"This application uses a Gradient Boosting Classifier model, which was trained on the `fetal_health.csv` dataset. \"\n",
        "    \"The dataset contains 21 features derived from Cardiotocogram (CTG) examinations, which are used to predict \"\n",
        "    \"one of three fetal health outcomes: Normal (1), Suspect (2), or Pathological (3).\"\n",
        ")\n",
        "st.markdown(\n",
        "    \"The data underwent preprocessing steps including outlier treatment using the IQR method (replacing outliers with the median) \"\n",
        "    \"and feature scaling using `StandardScaler`. The model was optimized through hyperparameter tuning \"\n",
        "    \"using GridSearchCV, selecting the Gradient Boosting Classifier as the best-performing model based on cross-validation accuracy.\"\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0645331b"
      },
      "source": [
        "##  Streamlit App Deployment\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9fb12ce"
      },
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Terminate any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Set the ngrok authtoken explicitly\n",
        "ngrok.set_auth_token(os.environ['NGROK_AUTH_TOKEN'])\n",
        "print(\"ngrok authtoken set.\")\n",
        "\n",
        "# 3. Run the Streamlit application in the background\n",
        "# We use subprocess to run streamlit in a non-blocking way.\n",
        "# Streamlit usually runs on port 8501 by default.\n",
        "streamlit_process = subprocess.Popen(['streamlit', 'run', 'app.py'],\n",
        "                                     stdout=subprocess.PIPE,\n",
        "                                     stderr=subprocess.PIPE,\n",
        "                                     bufsize=1, universal_newlines=True)\n",
        "\n",
        "print(\"Streamlit app started in the background. Waiting for it to become available...\")\n",
        "\n",
        "# Give Streamlit some time to start up\n",
        "time.sleep(5) # Adjust this if Streamlit takes longer to start\n",
        "\n",
        "# 4. Use pyngrok to establish a public URL for the Streamlit application\n",
        "# The ngrok.connect() method returns a Tunnel object\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "\n",
        "# 5. Print the public URL\n",
        "print(f\"Streamlit App URL: {public_url}\")\n",
        "print(\"You can access the Streamlit app using the URL above. If you want to stop the app and ngrok tunnel, run ngrok.kill() and terminate the kernel.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}